{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c7c7baae-5e0e-406a-9288-d5deb87e360a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# âœ… Package installation\n",
    "restart_required = False\n",
    "\n",
    "try:\n",
    "    import databricks.feature_engineering\n",
    "except ImportError:\n",
    "    %pip install databricks-feature-engineering\n",
    "    restart_required = True\n",
    "\n",
    "try:\n",
    "    import xgboost\n",
    "except ImportError:\n",
    "    %pip install xgboost\n",
    "    restart_required = True\n",
    "\n",
    "try:\n",
    "    import catboost\n",
    "except ImportError:\n",
    "    %pip install catboost\n",
    "    restart_required = True\n",
    "\n",
    "try:\n",
    "    import lightgbm\n",
    "except ImportError:\n",
    "    %pip install lightgbm\n",
    "    restart_required = True\n",
    "\n",
    "\n",
    "if restart_required:\n",
    "    dbutils.library.restartPython()\n",
    "else:\n",
    "    print(\"âœ… All required packages are already installed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41106f42-992c-4666-b062-62ae424830da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# âœ… Imports\n",
    "import pandas as pd\n",
    "from databricks.feature_engineering import FeatureEngineeringClient, FeatureLookup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4b482f3-9665-4d4e-a411-73833d3e746d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# âœ… Load feature + label data from feature store\n",
    "fe = FeatureEngineeringClient()\n",
    "\n",
    "\n",
    "# Load labels\n",
    "file_path = \"file:/Workspace/Users/yasodhashree91@gmail.com/oms-databricks/04_AI_ML/model_evaluation/classification/data_files/housing_loan.csv\"\n",
    "labels_df = spark.read.csv(file_path, header=True, inferSchema=True)\\\n",
    "    .select(\"LoanID\", \"IsDefault\")\\\n",
    "    .dropna(subset=[\"IsDefault\"])\n",
    "\n",
    "# Define feature lookup\n",
    "feature_lookups = [\n",
    "    FeatureLookup(\n",
    "        table_name=\"realestate.ml.loan_features\",\n",
    "        lookup_key=\"LoanID\"\n",
    "    )\n",
    "]\n",
    "\n",
    "# Create training set\n",
    "training_set = fe.create_training_set(\n",
    "    df=labels_df,\n",
    "    feature_lookups=feature_lookups,\n",
    "    label=\"IsDefault\",\n",
    "    exclude_columns=[\"LoanID\"]\n",
    ")\n",
    "\n",
    "# Load to pandas\n",
    "data = training_set.load_df().toPandas()    \n",
    "X = data.drop(columns=[\"IsDefault\"])            # Features (X)\n",
    "y = data[\"IsDefault\"]                           # Label (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "310bdb6d-f4b1-42a9-a4d1-1e3754ccfa4b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# âœ… Split Features (X) and Label (y) into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "\n",
    "# âœ… Model setup and configurations\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=50, max_depth=8, class_weight='balanced', n_jobs=-1, random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=100, max_depth=6),\n",
    "    \"CatBoost\": CatBoostClassifier(iterations=100, depth=6, verbose=False, allow_writing_files=False),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=3, weights='distance', n_jobs=-1),\n",
    "    \"LightGBM\": LGBMClassifier(n_estimators=100, max_depth=6, verbosity=-1),\n",
    "}\n",
    "\n",
    "# âœ… Training + evaluation\n",
    "for model_name, model_instance in models.items():\n",
    "    with mlflow.start_run(run_name=f\"classifier_{model_name}\"):\n",
    "        model_instance.fit(X_train, y_train)\n",
    "        \n",
    "        predictions = model_instance.predict(X_test)\n",
    "        \n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        precision = precision_score(y_test, predictions, zero_division=0)\n",
    "        recall = recall_score(y_test, predictions, zero_division=0)\n",
    "        f1 = f1_score(y_test, predictions, zero_division=0)\n",
    "        conf_matrix = confusion_matrix(y_test, predictions)\n",
    "\n",
    "        print(f\"Model: {model_name}\")\n",
    "        print(f\"Accuracy     : {accuracy:.4f}\")\n",
    "        print(f\"Precision    : {precision:.4f}\")\n",
    "        print(f\"Recall       : {recall:.4f}\")\n",
    "        print(f\"F1 Score     : {f1:.4f}\")\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(conf_matrix)\n",
    "        print(\"=\" * 80)\n",
    "\n",
    "        # Log model\n",
    "        fe.log_model(\n",
    "            model=model_instance,\n",
    "            artifact_path=model_name.replace(\" \", \"_\").lower(),\n",
    "            flavor=mlflow.sklearn,\n",
    "            training_set=training_set,\n",
    "            registered_model_name=\"realestate.ml.loan_default_classifier\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "faa79134-196b-4964-a4ce-e56f392d88d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### ðŸ“Š Classification Metrics Overview\n",
    "\n",
    "| **Metric**           | **Good When** | **What It Tells You**                                        |\n",
    "|----------------------|---------------|---------------------------------------------------------------|\n",
    "| **Accuracy**         | High          | Overall correctness                                            |\n",
    "| **Precision**        | High          | Model is good at avoiding false positives                     |\n",
    "| **Recall (Sensitivity)** | High      | Model is good at catching all true positives                  |\n",
    "| **F1 Score**         | High          | Balance between precision and recall                          |\n",
    "| **Confusion Matrix** | â€”             | Exact count of True Positives, False Positives, True Negatives, and False Negatives |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5a71b5b3-d0f8-4e3d-98d3-5a92e8c10ad1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### âœ… Understanding Confusion Matrix\n",
    "\n",
    "Confusion Matrix is generally displayed in this format:  \n",
    "`[[TN FP]`  \n",
    "&nbsp;&nbsp;`[FN TP]]`  \n",
    "\n",
    "Example:  \n",
    "`[[24068    23]`  \n",
    "&nbsp;&nbsp;`[   45  1090]]`\n",
    "\n",
    "\n",
    "\n",
    "This means:  \n",
    "- **24068** â†’ True Negatives (TN)  \n",
    "- **23**   â†’ False Positives (FP)  \n",
    "- **45**  â†’ False Negatives (FN)  \n",
    "- **1090**   â†’ True Positives (TP)  \n",
    "\n",
    "| **Term**            | **What It Means**                                                                                      | **Example (Loan Default Prediction)**                            |\n",
    "|---------------------|------------------------------------------------------------------------------------------------------|------------------------------------------------------------------|\n",
    "| **True Positive (TP)**  | Number of times model predicted **Yes**, and it was actually **Yes**                                 | Model said a person will default, and they **did**.               |\n",
    "| **False Positive (FP)** | Number of times model predicted **Yes**, but it was actually **No**                                  | Model said a person will default, but they **didn't** (False alarm). |\n",
    "| **True Negative (TN)**  | Number of times model predicted **No**, and it was actually **No**                                   | Model said a person won't default, and they **didn't**.           |\n",
    "| **False Negative (FN)** | Number of times model predicted **No**, but it was actually **Yes**                                  | Model said a person won't default, but they **did** (Missed case). |\n",
    "\n",
    "\n",
    "> ðŸ“Œ Think of TRUE values (True Positives and True Negatives) as correct predictions, and FALSE values (False Positives and False Negatives) as incorrect predictions. A model with many True Positives and True Negatives is likely performing well, while many False Positives and False Negatives suggest poor performance.\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02_model_training",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
