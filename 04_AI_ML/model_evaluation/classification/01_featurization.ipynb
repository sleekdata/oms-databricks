{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3102ca45-c133-49bc-8ba7-31c64314aa4f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Install the databricks-feature-engineering package if not already installed\n",
    "try:\n",
    "    import databricks.feature_engineering\n",
    "    print(\"Package already installed.\")\n",
    "except ImportError:\n",
    "    print(\"Installing package...\")\n",
    "    %pip install databricks-feature-engineering\n",
    "    dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a15a2531-dbf0-4457-b101-c4284f1ecf54",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from databricks.feature_engineering import FeatureEngineeringClient\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50a397db-5260-49a1-b7a3-052a00d0ea5c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load data\n",
    "file_path = \"file:/Workspace/Users/yasodhashree91@gmail.com/oms-databricks/04_AI_ML/model_evaluation/classification/data_files/housing_loan.csv\"\n",
    "loan_df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "\n",
    "# Display sample\n",
    "loan_df.limit(5).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1d26cdf-eba7-45b5-8981-6c802ed8ffae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Drop target column for feature prep\n",
    "features_df = loan_df.drop(\"IsDefault\")\n",
    "\n",
    "# Drop rows with any nulls\n",
    "features_df = features_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94dd7a3e-b472-4bfb-9d91-c399a277cdef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "Categoricals = ['HasCoSigner','HasDependents', 'HasMortgage',\n",
    "           'MaritalStatus', 'EmploymentType', 'Education']\n",
    "\n",
    "for col in Categoricals:\n",
    "    indexer = StringIndexer(inputCol=col, outputCol=f\"{col}_idx\")\n",
    "    features_df = indexer.fit(features_df).transform(features_df)\n",
    "\n",
    "# If you want to drop original columns and rename indexed columns back:\n",
    "for col in Categoricals:\n",
    "    features_df = features_df.drop(col)\n",
    "\n",
    "features_df.limit(5).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "741e1013-7146-4165-b373-26f127ecb2b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Save to feature store\n",
    "fe = FeatureEngineeringClient()\n",
    "\n",
    "feature_table_name = \"realestate.feature_store.loan_features\"\n",
    "\n",
    "\n",
    "# Drop if exists\n",
    "try:\n",
    "    fe.drop_table(name=feature_table_name)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Create feature table\n",
    "fe.create_table(\n",
    "    name=feature_table_name,\n",
    "    primary_keys=[\"LoanID\"],\n",
    "    df=features_df,\n",
    "    description=\"Processed housing loan features for classification\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81be38a0-1403-40f0-ae06-6fdbac5f0cd9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Confirm saved\n",
    "display(spark.table(\"realestate.feature_store.loan_features\").limit(5))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "01_featurization",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
