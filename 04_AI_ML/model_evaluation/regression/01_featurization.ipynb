{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e38d457b-615c-4650-8215-d4ae3e965ed8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Note: Use ML-supported clusters (labeled as \"X.Y LTS ML\" e.g., \"13.3 LTS ML\") for machine learning workloads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36a65ad5-9616-4e8d-8ad9-3654949591ab",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Imports"
    }
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from pyspark.sql.functions import current_date, year, col\n",
    "from pyspark.sql.types import StructType, StructField, DoubleType, IntegerType\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.functions import vector_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15dd42d0-d59c-4894-8f79-1102689b97ea",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "# Load housing dataset from CSV"
    }
   },
   "outputs": [],
   "source": [
    "# Load Housing Data from CSV\n",
    "# base_file_path = \"file:/Workspace/Users/yasodhashree91@gmail.com/oms-databricks/04_AI_ML/feature_eng/data_files/\"\n",
    "# housing_df = spark.read.csv(base_file_path + \"housing.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Display first 5 rows for understanding\n",
    "# print(\"Housing Data Preview:\")\n",
    "# housing_df.limit(5).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90da70c7-ecb5-4ed3-a364-3d74e141a921",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create Sample Housing Data"
    }
   },
   "outputs": [],
   "source": [
    "# Manually define housing data if reading from CSV is not working\n",
    "from pyspark.sql.types import StructType, StructField, DoubleType, IntegerType\n",
    "\n",
    "# Define schema\n",
    "schema = StructType([\n",
    "    StructField(\"House_ID\", IntegerType(), True),\n",
    "    StructField(\"Square_Feet\", DoubleType(), True),\n",
    "    StructField(\"Num_Bedrooms\", IntegerType(), True),\n",
    "    StructField(\"Num_Bathrooms\", IntegerType(), True),\n",
    "    StructField(\"Num_Floors\", IntegerType(), True),\n",
    "    StructField(\"Year_Built\", IntegerType(), True),\n",
    "    StructField(\"Has_Garden\", IntegerType(), True),\n",
    "    StructField(\"Has_Pool\", IntegerType(), True),\n",
    "    StructField(\"Garage_Size\", IntegerType(), True),\n",
    "    StructField(\"Location_Score\", DoubleType(), True),\n",
    "    StructField(\"Distance_to_Center\", DoubleType(), True),\n",
    "    StructField(\"Price\", DoubleType(), True)\n",
    "])\n",
    "\n",
    "# Create data (extend as many as you needed)\n",
    "data = [\n",
    "    (1, 143.63502971184062, 1, 3, 3, 1967, 1, 1, 48, 8.297631202876449, 5.935733640397012, 602134.816746586),\n",
    "    (2, 287.67857660247904, 1, 2, 1, 1949, 0, 1, 37, 6.061465649334798, 10.827392203145374, 591425.1353862194),\n",
    "    (3, 232.99848545285127, 1, 3, 2, 1923, 1, 0, 14, 2.9114424778517902, 6.904599073399449, 464478.6968798775),\n",
    "    (4, 199.66462104925915, 5, 2, 2, 1918, 0, 0, 17, 2.0709491817657124, 8.284018511436607, 583105.655996478),\n",
    "    (5, 89.00466011060914, 4, 3, 3, 1999, 1, 0, 34, 1.523277856626788, 14.648277296253372, 619879.1425227895)\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "housing_df = spark.createDataFrame(data, schema=schema)\n",
    "\n",
    "# Display preview\n",
    "display(housing_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b658403a-e956-489f-b01c-46a842869208",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create House Age Feature"
    }
   },
   "outputs": [],
   "source": [
    "# Drop the target label column before handling missing values in the features\n",
    "features_df = housing_df.drop(\"Price\")\n",
    "\n",
    "# Drop rows with any null values in the features\n",
    "features_df = features_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3fa85272-7d69-4d0e-8032-8de235d376e5",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Scale numeric features"
    }
   },
   "outputs": [],
   "source": [
    "numeric_cols = [\"Square_Feet\", \"Num_Bedrooms\", \"Num_Bathrooms\", \"Num_Floors\", \n",
    "                \"Garage_Size\", \"Location_Score\", \"Distance_to_Center\", \"House_Age\"]\n",
    "\n",
    "assembler = VectorAssembler(inputCols=numeric_cols, outputCol=\"features_vec\")\n",
    "scaler = StandardScaler(inputCol=\"features_vec\", outputCol=\"scaled_features\", withMean=True, withStd=True)\n",
    "\n",
    "pipeline = Pipeline(stages=[assembler, scaler])\n",
    "scaler_model = pipeline.fit(housing_df)\n",
    "housing_df_scaled = scaler_model.transform(housing_df)\n",
    "\n",
    "housing_df_scaled = housing_df_scaled.withColumn(\"scaled_features_array\", vector_to_array(\"scaled_features\"))\n",
    "\n",
    "# Add scaled columns back\n",
    "for i, col_name in enumerate(numeric_cols):\n",
    "    housing_df_scaled = housing_df_scaled.withColumn(f\"scaled_{col_name}\", col(\"scaled_features_array\")[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c98f352-2db4-4eac-ab64-30fe073e1b58",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Select only required columns (drop others)"
    }
   },
   "outputs": [],
   "source": [
    "# Select required columns for feature store\n",
    "final_cols = [\"House_ID\", \"Has_Garden\", \"Has_Pool\"] + [f\"scaled_{col}\" for col in numeric_cols]\n",
    "\n",
    "housing_features_final = housing_df_scaled.select(final_cols)\n",
    "\n",
    "# Display final feature table\n",
    "print(\"Final Features for Feature Store:\")\n",
    "housing_features_final.limit(5).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8adc9a15-0854-4b64-b9e8-711d2bf17825",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Save Features to Databricks Feature Store\n",
    "\n",
    "fe = FeatureEngineeringClient()\n",
    "\n",
    "feature_table_name = \"housing.feature_store.housing_features\"\n",
    "\n",
    "# Drop existing table (if any)\n",
    "try:\n",
    "    fe.drop_table(name=feature_table_name)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Create feature table\n",
    "fe.create_table(\n",
    "    name=feature_table_name,\n",
    "    primary_keys=[\"House_ID\"],\n",
    "    df=housing_features_final,\n",
    "    description=\"Housing features for price prediction\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "01_featurization",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
